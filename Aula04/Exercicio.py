# -*- coding: utf-8 -*-
"""Exercicio.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16piSTV2zC9I0znQuCNiWVkcuD-cQ-ti8
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.model_selection import train_test_split, learning_curve

dataset = pd.read_csv('../datasets/Dataset_3Cluster_4features.csv')

dataset.head()

dataset.describe()

X = dataset.drop(columns='V5').values
Y = dataset[['V5']].values.ravel()

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)

"""## SKLearn"""

from sklearn.neural_network import MLPClassifier

clf1 = MLPClassifier(hidden_layer_sizes=(2), random_state=42)
clf1.fit(X_train, Y_train)
print(clf1.score(X_test, Y_test))
plt.plot(clf1.loss_curve_)

clf2 = MLPClassifier(hidden_layer_sizes=(7), random_state=42)
clf2.fit(X_train, Y_train)
print(clf2.score(X_test, Y_test))
plt.plot(clf2.loss_curve_)

clf3 = MLPClassifier(hidden_layer_sizes=(8), random_state=42)
clf3.fit(X_train, Y_train)
print(clf3.score(X_test, Y_test))
plt.plot(clf3.loss_curve_)

clf4 = MLPClassifier(hidden_layer_sizes=(2), learning_rate_init=0.1, random_state=42)
clf4.fit(X_train, Y_train)
print(clf4.score(X_test, Y_test))
plt.plot(clf4.loss_curve_)

"""## Keras"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.utils import to_categorical

model1 = Sequential()
model1.add(Dense(2, activation='relu', input_dim=X.shape[1]),)
model1.add(Dense(4, activation='softmax'))

optimizer = Adam()
model1.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])
history = model1.fit(X_train, to_categorical(Y_train), 32, 5, validation_split=0, shuffle=False, verbose=0)
score = model1.evaluate(X_test, to_categorical(Y_test), batch_size=128)
print(score[1])
plt.plot(history.history['loss'])

model1 = Sequential()
model1.add(Dense(7, activation='relu', input_dim=X.shape[1]),)
model1.add(Dense(4, activation='softmax'))

optimizer = Adam()
model1.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])
history = model1.fit(X_train, to_categorical(Y_train), 32, 5, validation_split=0, shuffle=False, verbose=0)
score = model1.evaluate(X_test, to_categorical(Y_test), batch_size=128)
print(score[1])
plt.plot(history.history['loss'])

model1 = Sequential()
model1.add(Dense(2, activation='relu', input_dim=X.shape[1]),)
model1.add(Dense(4, activation='softmax'))

optimizer = Adam()
model1.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])
history = model1.fit(X_train, to_categorical(Y_train), 32, 10, validation_split=0, shuffle=False, verbose=0)
score = model1.evaluate(X_test, to_categorical(Y_test), batch_size=128)
print(score[1])
plt.plot(history.history['loss'])

model1 = Sequential()
model1.add(Dense(2, activation='relu', input_dim=X.shape[1]),)
model1.add(Dense(4, activation='softmax'))

optimizer = Adam(lr=0.1)
model1.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])
history = model1.fit(X_train, to_categorical(Y_train), 32, 5, validation_split=0, shuffle=False, verbose=0)
score = model1.evaluate(X_test, to_categorical(Y_test), batch_size=128)
print(score[1])
plt.plot(history.history['loss'])

model1 = Sequential()
model1.add(Dense(2, activation='relu', input_dim=X.shape[1]),)
model1.add(Dense(4, activation='softmax'))

optimizer = Adam(lr=0.1)
model1.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])
history = model1.fit(X_train, to_categorical(Y_train), 32, 10, validation_split=0, shuffle=False, verbose=0)
score = model1.evaluate(X_test, to_categorical(Y_test), batch_size=128)
print(score[1])
plt.plot(history.history['loss'])

model1 = Sequential()
model1.add(Dense(2, activation='relu', input_dim=X.shape[1]),)
model1.add(Dense(4, activation='softmax'))

optimizer = Adam(lr=0.1)
model1.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])
history = model1.fit(X_train, to_categorical(Y_train), 32, 15, validation_split=0, shuffle=False, verbose=0)
score = model1.evaluate(X_test, to_categorical(Y_test), batch_size=128)
print(score[1])
plt.plot(history.history['loss'])